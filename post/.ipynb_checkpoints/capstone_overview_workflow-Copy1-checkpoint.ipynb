{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Project Statement / DS Question:\n",
    "* Can a Convolutional Neural Network (ConvNet) be used to identify malignant cancer from histopathology slides? How can the ConvNet be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Labeled Dataset 1:\n",
    ">Classification of breast cancer histology images using Convolutional Neural Networks\n",
    "\n",
    "    >http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0177544s\n",
    "\n",
    "    - resolution: 2040x1536px\n",
    "    - from _BioImaging 2015 breast histology classification challenge_\n",
    "    - four balanced classes: \n",
    "                normal, \n",
    "                benign lesion, \n",
    "                _in situ_ carcinoma, \n",
    "                invasive carcinoma \n",
    "    - dataset composition: 249 image training set and 20 image test set\n",
    " \n",
    "2. Labeled Dataset 2: \n",
    "> Spanhol, F., Oliveira, L. S., Petitjean, C., Heutte, L., A Dataset for Breast Cancer Histopathological Image Classification, IEEE Transactions on Biomedical Engineering (TBME), 63(7):1455-1462, 2016. [pdf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow for #1 \n",
    "\n",
    "    - CNN and CNN+SVM used to calculate patch-wise class probability.\n",
    "\n",
    "Image-wise classification:\n",
    "\n",
    "    i. majority vote - most common patch label is chosen\n",
    "    ii. maximum probability - patch with higher class prob\n",
    "    iii. sum of probabilities - class probabilities summed  and largest chosen\n",
    "\n",
    "1. Try the Augmented Patch Dataset\n",
    "   >An augmented patch dataset is created from the normalized images in the training set. The\n",
    "used dataset has a low number of samples when compared to other CNN classification problems\n",
    "[18]. The network might thus be prone to overfit. Dividing images into patches allows to\n",
    "increase the dataset complexity and dimension. Data augmentation through patch rotation\n",
    "and mirroring further improves the dataset. This is possible because the studied problem is\n",
    "rotation invariant, i.e., physicians can study breast cancer histological images from different\n",
    "orientations without altering the diagnosis. Consequently, rotations and mirroring allow to\n",
    "increase the size of the dataset without deteriorating its quality. Patching and dataset augmentation\n",
    "have already been used successfully on similar histological classification problems [19].\n",
    "However, they have not been used for carcinoma classification.\n",
    "First, the image is divided in patches of 512 × 512 pixels size, with 50% overlap. Some example\n",
    "patches are shown in Fig 1. Patch normalization is performed by subtracting the average\n",
    "value to the red, green and blue channels separately. Each patch is then transformed into eight\n",
    "different patches by combining k \u0001 π/2 rotations, with k = {0, 1, 2, 3}, and vertical reflections.\n",
    "This results in a total of 70000 different patches from the original 250 training images. Each of\n",
    "the patches is considered to have the same class label as the original image.\n",
    "    >> PLOSone paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras includes a class to handle data augmentation: `ImageDataGenerator` \n",
    ">_Deep Learning with Python_, Chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndatagen = ImageDataGenerator(\\n   rotation_range=40,         # value in degrees (0-180) to rotate pictures\\n   width_shift_range=0.2,     # fractions by which to translate the image\\n   height_shift_range=0.2,    # fractions by which to translate the image  \\n   shear_range=0.2,           # shearing transformations\\n   zoom_range=0.2,            # zooming inside pictures\\n   horizontal_flip=True,      # flip half the image horizaontally when there is  no assunmption of horizontal asymmetry\\n   fill_mode='nearest')       # strategy for filling in newly created pixels resulting from transformation\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=90,         # value in degrees (0-180) to rotate pictures\n",
    "   validation_split = .20,    # reserve 20% of training set as validation\n",
    "   width_shift_range=0.2,     # fractions by which to translate the image\n",
    "   height_shift_range=0.2,    # fractions by which to translate the image  \n",
    "   shear_range=0.2,           # shearing transformations\n",
    "   zoom_range=0.2,            # zooming inside pictures\n",
    "   horizontal_flip=True,      # flip half the image horizaontally \n",
    "   fill_mode='nearest')       # strategy for filling in newly created pixels \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Net Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net\n",
    "![U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
    "\n",
    "### PLOSone Paper\n",
    "![PLOSone](http://journals.plos.org/plosone/article/figure/image?size=large&id=10.1371/journal.pone.0177544.g003)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0. Input... 512,512,3  ...(BatchNormalization layer?) \n",
    "    --> https://arxiv.org/pdf/1502.03167.pdf \n",
    "        \"BatchNormalization: Acc. Deep Network Training by Reducing Internal Covariate Shift\"\n",
    "1.      BATCHNORMALIZATION\n",
    "2. Conv ... 510,510,16 ... 3x3 valid  --> relu\n",
    "\n",
    "3. MP   ... 170,170,16 ... 3x3 valid\n",
    "4. Conv ... 168,168,32 ... 3x3 valid  --> relu\n",
    "5. MP   ... 84,84,32   ... 2x2 valid\n",
    "6. Conv ... 84,84,64   ... 3x3 same   --> relu\n",
    "7. MP   ... 42,42,64   ... 2x2 valid \n",
    "8. Conv ... 42,42,64   ... 3x3 same   --> relu\n",
    "9. MP   ... 14,14,64   ... 3x3 valid\n",
    "10. Conv ... 12,12,32  ... 3x3 valid  --> relu\n",
    "11. MP  ... 12,12,32   ... 3x3 valid\n",
    "12.    FLATTEN\n",
    "13. FC  ... 256\n",
    "14. FC  ... 128\n",
    "15. FC  ... 4                         --> softmax\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
